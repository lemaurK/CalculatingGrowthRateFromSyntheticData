{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413620ea",
   "metadata": {},
   "source": [
    "#  Extracting Statistical Information from AFM Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed309d",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92db312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "from findpeaks import findpeaks as findpeaks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665cc7d",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fcde834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extpected input: Outputted cross sectional data matrix from Pygwy script,\n",
    "# pass the pixel dimension of your image as the value for n, defaulted to 512 representing a SQUARE 512x512 image.\n",
    "# Expected Output: Nested list, containing lists of a row-wise breakup of the inital matrix of size n by n.\n",
    "def SplitDataMatrixIntoRows(data, pixel_dimension_of_image=512):\n",
    "    nested_list_of_individual_cross_sections = list()\n",
    "    for i in range(0, len(data), pixel_dimension_of_image):\n",
    "        nested_list_of_individual_cross_sections.append(data[i:i + pixel_dimension_of_image])\n",
    "    return np.array(nested_list_of_individual_cross_sections)\n",
    "\n",
    "# Expected input: Output from SplitDataMatrixIntoRows(),\n",
    "# pass the physical length of your image in micrometers as \"length_in_micrometers\" and the same pixel dimension as \n",
    "# inputted into SplitDataMatrixIntoRows(), defaulted to length_in_micrometers=6 and pixel_dimension_of_image=512.\n",
    "# Expected Output: Nested list containing lists of x-axis locations of negative peaks (relative minima)\n",
    "def ExtractDistancesBetweenRelativeMinima_GrainDiameter(data, length_in_micrometers=6, pixel_dimension_of_image=512):\n",
    "    scaling_factor = length_in_micrometers/pixel_dimension_of_image\n",
    "    nested_list_of_xaxis_locations_of_relative_minima_for_each_cross_section = list()\n",
    "    for each_individual_cross_section in data:\n",
    "        xaxis_locations_of_relative_minima = argrelextrema(each_individual_cross_section, np.less)\n",
    "        xaxis_locations_of_relative_minima = xaxis_locations_of_relative_minima[0]\n",
    "        xaxis_locations_of_relative_minima = xaxis_locations_of_relative_minima*scaling_factor\n",
    "        nested_list_of_xaxis_locations_of_relative_minima_for_each_cross_section.append(xaxis_locations_of_relative_minima)\n",
    "    return nested_list_of_xaxis_locations_of_relative_minima_for_each_cross_section\n",
    "    \n",
    "# Expected Input: Output from ExtractDistancesBetweenRelativeMinima_GrainDiameter()  \n",
    "# Expected Output: Two floats: The average grain diameter for all grains in the image and the standard deviation.  \n",
    "def CalculateAverageAndStandardDeviation_GrainDiameter(data):\n",
    "    list_of_grain_diameters_for_all_cross_sections = list()\n",
    "    for each_list_of_relative_minima_locations in data:\n",
    "        list_of_individual_diameters = np.diff(each_list_of_relative_minima_locations)\n",
    "        list_of_grain_diameters_for_all_cross_sections.append(list_of_individual_diameters)\n",
    "    list_of_grain_diameters_for_all_cross_sections = np.concatenate(list_of_grain_diameters_for_all_cross_sections).ravel()\n",
    "    average_diameter = np.mean(list_of_grain_diameters_for_all_cross_sections)\n",
    "    standard_deviation_diameter = np.std(list_of_grain_diameters_for_all_cross_sections)\n",
    "    return average_diameter,standard_deviation_diameter\n",
    "\n",
    "# Expected Input: Output from SplitDataMatrixIntoRows().\n",
    "# Expected Output: Nested list containing heights of individual grains.\n",
    "def ExtractHeightOfRelativeMaxima_GrainHeight(data):\n",
    "    nested_list_of_grain_heights = list()\n",
    "    for each_individual_cross_section in data:\n",
    "        individual_heights = each_individual_cross_section[argrelextrema(each_individual_cross_section, np.greater)[0]]\n",
    "        nested_list_of_grain_heights.append(individual_heights)\n",
    "    return nested_list_of_grain_heights\n",
    "\n",
    "# Expected Input: Output from ExtractHeightOfRelativeMaxima_GrainHeight()\n",
    "# Expected Output: Two floats: The average grain height for all grains in the image and the standard devaiton.\n",
    "def CalculateAverageAndStandardDeviation_GrainHeight(data):\n",
    "    list_of_grain_heights_for_all_cross_sections = np.concatenate(data).ravel()\n",
    "    average_height = np.mean(list_of_grain_heights_for_all_cross_sections)\n",
    "    standard_deviation_height = np.std(list_of_grain_heights_for_all_cross_sections)\n",
    "    return average_height,standard_deviation_height\n",
    "\n",
    "# Expected Input: Output from ExtractDistancesBetweenRelativeMinima_GrainDiameter()\n",
    "# Expected Output: Four floats: The average maximum grain diameter from each cross section and the standard deviation.\n",
    "# The average minimum grain diameter from each cross section and the standard deviation.\n",
    "def CalculateAverageAndStandardDeviationOfMaximumAndMinimumGrainDiameter(data):\n",
    "    list_of_maximum_grain_diameter_from_each_cross_section = list()\n",
    "    list_of_minimum_grain_diameter_from_each_cross_section = list()\n",
    "    for each_individual_cross_section in data:\n",
    "        list_of_individual_diameters = np.diff(each_individual_cross_section)\n",
    "        list_of_maximum_grain_diameter_from_each_cross_section.append(max(list_of_individual_diameters))\n",
    "        list_of_minimum_grain_diameter_from_each_cross_section.append(min(list_of_individual_diameters))\n",
    "    average_maximum_grain_diameter = np.mean(list_of_maximum_grain_diameter_from_each_cross_section)\n",
    "    standard_deviation_of_maximum_grain_diameter = np.std(list_of_maximum_grain_diameter_from_each_cross_section)\n",
    "    average_minimum_grain_diameter = np.mean(list_of_minimum_grain_diameter_from_each_cross_section)\n",
    "    standard_deviation_of_minimum_grain_diameter = np.std(list_of_minimum_grain_diameter_from_each_cross_section)\n",
    "    return average_maximum_grain_diameter, standard_deviation_of_maximum_grain_diameter, average_minimum_grain_diameter, standard_deviation_of_minimum_grain_diameter\n",
    "\n",
    "# Expected Input: Output from ExtractHeightOfRelativeMaxima_GrainHeight()\n",
    "# Expected Output: Four floats: The average maximum grain height from each cross section and the standard deviation.\n",
    "# The average minimum grain height from each cross section and the standard deviation.\n",
    "def CalculateAverageAndStandardDeviationOfMaximumAndMinimumGrainHeight(data):\n",
    "    list_of_maximum_grain_heights_from_each_cross_section = list()\n",
    "    list_of_minimum_grain_heights_from_each_cross_section = list()\n",
    "    for each_individual_cross_section in data:\n",
    "        list_of_maximum_grain_heights_from_each_cross_section.append(max(each_individual_cross_section))\n",
    "        list_of_minimum_grain_heights_from_each_cross_section.append(min(each_individual_cross_section))\n",
    "    average_maximum_grain_height = np.mean(list_of_maximum_grain_heights_from_each_cross_section)\n",
    "    standard_deviation_of_maximum_grain_heights = np.std(list_of_maximum_grain_heights_from_each_cross_section)\n",
    "    average_minimum_grain_height = np.mean(list_of_minimum_grain_heights_from_each_cross_section)\n",
    "    standard_deviation_of_minimum_grain_heights = np.std(list_of_minimum_grain_heights_from_each_cross_section)\n",
    "    return average_maximum_grain_height, standard_deviation_of_maximum_grain_heights, average_minimum_grain_height, standard_deviation_of_minimum_grain_heights\n",
    "\n",
    "def process_morphology_return_data_only(morphology_title, list_of_scans, times, length_in_micrometers=6, pixel_dimension_of_image=512):\n",
    "    scaling_factor = length_in_micrometers / pixel_dimension_of_image\n",
    "    fp = findpeaks(method='topology', whitelist='peak')\n",
    "    scan_data = dict()\n",
    "    peak_y_cordinates = list()\n",
    "    data = {\"mu_n_grains\":list(),\n",
    "            \"sigma_n_grains\":list(),\n",
    "            \"mu_grain_width\":list(),\n",
    "            \"sigma_grain_width\":list(),\n",
    "            \"mu_grain_amp\":list(),\n",
    "            \"sigma_grain_amp\":list()}\n",
    "    \n",
    "    for index, scan in list_of_scans.items():\n",
    "        fit = fp.fit(scan)\n",
    "        list_of_peak_cordinates = fit['groups0']\n",
    "        for peak in list_of_peak_cordinates:\n",
    "            if peak[2] != 0.0:\n",
    "                peak_y_cordinates.append(peak[0][0])\n",
    "                    \n",
    "        list_of_crosssections_with_peaks = [scan[i] for i in list(set(peak_y_cordinates))]\n",
    "        \n",
    "        scan_mean_n_grains, scan_std_n_grains = len(list_of_peak_cordinates), 1\n",
    "        \n",
    "        scan_diams = ExtractDistancesBetweenRelativeMinima_GrainDiameter(list_of_crosssections_with_peaks)\n",
    "        scan_mean_diameter, scan_std_diameter = CalculateAverageAndStandardDeviation_GrainDiameter(scan_diams)\n",
    "        \n",
    "        scan_height = ExtractHeightOfRelativeMaxima_GrainHeight(list_of_crosssections_with_peaks)\n",
    "        scan_mean_height, scan_std_height = CalculateAverageAndStandardDeviation_GrainHeight(scan_height)\n",
    "        \n",
    "        collection = [scan_mean_n_grains, scan_std_n_grains,\n",
    "                      (scan_mean_diameter/scaling_factor)/2, (scan_std_diameter/scaling_factor)/10,\n",
    "                      (scan_mean_height/scaling_factor)/10, (scan_std_height/scaling_factor)/100]\n",
    "        \n",
    "        for entry, index in zip(collection, data.keys()): \n",
    "            data[index].append(entry)\n",
    "            \n",
    "    data['times(min)'] = list(times)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd0a2f",
   "metadata": {},
   "source": [
    "## Opening AFM Scan Data (2d arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e759795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_files(file_names, scan_title):\n",
    "    temp = dict()\n",
    "    for name in file_names:\n",
    "        with open(f'../../UR_la_plante/CaCO3 Gwyddion Python/gwyddion_scripts/gwy_data/{name}_full.txt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = list(reader)\n",
    "            data = np.array(data[0])\n",
    "            exec(f'{name}_raw_data = data.astype(float)')\n",
    "            \n",
    "    for name in file_names:\n",
    "        exec(f'{name}_divided = SplitDataMatrixIntoRows({name}_raw_data)')\n",
    "        exec(f'temp[name] = {name}_divided')\n",
    "        \n",
    "    for key, array in temp.items():\n",
    "        array = np.vstack([array, array[0]])\n",
    "        temp[key] = array\n",
    "        \n",
    "    return temp       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a82af",
   "metadata": {},
   "source": [
    "Open all files for the C11 Carbon Chain morphology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0592c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "c11_scan_title = 'C11'\n",
    "c11_times = np.array([5, 14, 31, 77, 130])\n",
    "c11_file_names = ['c11_5','c11_14','c11_31','c11_77','c11_130']\n",
    "\n",
    "c11_all_scans = open_files(c11_file_names, c11_scan_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a928dd",
   "metadata": {},
   "source": [
    "Open all files for the C11OH Carbon Chain morphology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c08e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "c11OH_scan_title = 'C11OH'\n",
    "c11OH_times = np.array([4, 18, 66, 100])\n",
    "c11OH_file_names = ['c11OH_4', 'c11OH_18', 'c11OH_66', 'c11OH_100']\n",
    "\n",
    "c11OH_all_scans = open_files(c11OH_file_names, c11OH_scan_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3e76b",
   "metadata": {},
   "source": [
    "Open all files for the C11NF Carbon Chain morphology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c287d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "c11NF_scan_title = 'C11NF'\n",
    "c11NF_times = np.array([6, 23, 51, 84, 102])\n",
    "c11NF_file_names = ['c11NF_6', 'c11NF_23', 'c11NF_51', 'c11NF_84', 'c11NF_102']\n",
    "\n",
    "c11NF_all_scans = open_files(c11NF_file_names, c11NF_scan_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71556a9a",
   "metadata": {},
   "source": [
    "## Initializing Data Generation Parameters\n",
    "Utilizing the \"Findpeaks\" Python package we will make a function that returns statistical information that will be passed in as parameters to output synthetic data generation functions necessary to generate representative data.\n",
    "\n",
    "**Module Docs for reference:** https://erdogant.github.io/findpeaks/pages/html/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a8eeb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n"
     ]
    }
   ],
   "source": [
    "# Running our data through the function.\n",
    "c11_morph_stats = process_morphology_return_data_only(c11_scan_title, c11_all_scans, c11_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa02877e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n"
     ]
    }
   ],
   "source": [
    "c11OH_morph_stats = process_morphology_return_data_only(c11OH_scan_title, c11OH_all_scans, c11OH_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8dd7ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n",
      "[findpeaks] >Finding peaks in 2d-array using topology method..\n",
      "[findpeaks] >Scaling image between [0-255] and to uint8\n",
      "[findpeaks] >Conversion to gray image.\n",
      "[findpeaks] >WARNING: Conversion to gray not possible.\n",
      "[findpeaks] >Denoising with [fastnl], window: [3].\n",
      "[findpeaks] >Detect peaks using topology method with limit at None.\n",
      "[findpeaks] >Fin.\n"
     ]
    }
   ],
   "source": [
    "c11NF_morph_stats = process_morphology_return_data_only(c11NF_scan_title, c11NF_all_scans, c11NF_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a044126",
   "metadata": {},
   "source": [
    "## Export Statistical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8095df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"statistical_data//c11_morph_stats.csv\", \"w\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(c11_morph_stats.keys())\n",
    "    writer.writerows(zip(*c11_morph_stats.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38d90ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu_n_grains</th>\n",
       "      <th>sigma_n_grains</th>\n",
       "      <th>mu_grain_width</th>\n",
       "      <th>sigma_grain_width</th>\n",
       "      <th>mu_grain_amp</th>\n",
       "      <th>sigma_grain_amp</th>\n",
       "      <th>times(min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>7.629606</td>\n",
       "      <td>0.818005</td>\n",
       "      <td>446.671242</td>\n",
       "      <td>14.579432</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2336</td>\n",
       "      <td>1</td>\n",
       "      <td>5.964128</td>\n",
       "      <td>0.718330</td>\n",
       "      <td>690.371578</td>\n",
       "      <td>17.060765</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>551</td>\n",
       "      <td>1</td>\n",
       "      <td>9.468574</td>\n",
       "      <td>1.099737</td>\n",
       "      <td>638.629809</td>\n",
       "      <td>17.527080</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>7.886063</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>660.868158</td>\n",
       "      <td>18.158011</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mu_n_grains  sigma_n_grains  mu_grain_width  sigma_grain_width  \\\n",
       "0          879               1        7.629606           0.818005   \n",
       "1         2336               1        5.964128           0.718330   \n",
       "2          551               1        9.468574           1.099737   \n",
       "3         1306               1        7.886063           0.928313   \n",
       "\n",
       "   mu_grain_amp  sigma_grain_amp  times(min)  \n",
       "0    446.671242        14.579432           4  \n",
       "1    690.371578        17.060765          18  \n",
       "2    638.629809        17.527080          66  \n",
       "3    660.868158        18.158011         100  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('statistical_data/c11OH_morph_stats.csv') as f:\n",
    "    df_c11 = pd.read_csv(f)\n",
    "    #df_c11 = df_c11.T.to_dict('list')\n",
    "df_c11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946159c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"statistical_data//c11OH_morph_stats.csv\", \"w\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(c11OH_morph_stats.keys())\n",
    "    writer.writerows(zip(*c11OH_morph_stats.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e6464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"statistical_data//c11NF_morph_stats.csv\", \"w\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(c11NF_morph_stats.keys())\n",
    "    writer.writerows(zip(*c11NF_morph_stats.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
